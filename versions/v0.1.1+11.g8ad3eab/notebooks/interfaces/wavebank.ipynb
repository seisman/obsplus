{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveBank\n",
    "`WaveBank` is an in-process database for accessing seismic time-series data. Any directory structure containing obspy-readable waveforms can be used as the data source. `WaveBank` uses a simple indexing scheme and the [Hierarchical Data Format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) to keep track of each `Trace` in the directory.\n",
    "\n",
    "For example, after downloading seismic data with [obspy's fdsn mass download](https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.mass_downloader.html), you need a way to access the data. You could manually read in each file but this can become very tedious and clutters up your application code with data access code. Enter WaveBank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a WaveBank object\n",
    "We will use the [Crandall Canyon](https://en.wikipedia.org/wiki/Crandall_Canyon_Mine) dataset from [ObsPlus' datasets](../datasets/datasets.ipynb) to create a new `WaveBank` instance. This will ensure the waveforms have been downloaded (to the obsplus installation directory), copy the dataset to a temporary directory, and initialize a `WaveBank` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:42:12.282245Z",
     "iopub.status.busy": "2020-09-23T18:42:12.281262Z",
     "iopub.status.idle": "2020-09-23T18:42:13.360124Z",
     "shell.execute_reply": "2020-09-23T18:42:13.359483Z"
    }
   },
   "outputs": [],
   "source": [
    "import obsplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:42:13.373841Z",
     "iopub.status.busy": "2020-09-23T18:42:13.372321Z",
     "iopub.status.idle": "2020-09-23T18:43:13.806642Z",
     "shell.execute_reply": "2020-09-23T18:43:13.805494Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Make sure the crandall canyone dataset is loaded and supress output.\n",
    "crandall = obsplus.load_dataset('crandall_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:13.810918Z",
     "iopub.status.busy": "2020-09-23T18:43:13.810045Z",
     "iopub.status.idle": "2020-09-23T18:43:13.855692Z",
     "shell.execute_reply": "2020-09-23T18:43:13.855209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The waveform path is: /tmp/tmp1llg3ak4/crandall_test/waveforms\n"
     ]
    }
   ],
   "source": [
    "# create a copy of the crandall dataset, storing the copied files in a temporary directory\n",
    "crandall = obsplus.copy_dataset('crandall_test')\n",
    "# a directory of waveforms now lives here:\n",
    "waveform_path = crandall.waveform_path\n",
    "print(f\"The waveform path is: {waveform_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to feed the path of the waveform files to the WaveBank constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:13.865497Z",
     "iopub.status.busy": "2020-09-23T18:43:13.860368Z",
     "iopub.status.idle": "2020-09-23T18:43:13.880871Z",
     "shell.execute_reply": "2020-09-23T18:43:13.880411Z"
    }
   },
   "outputs": [],
   "source": [
    "bank = obsplus.WaveBank(waveform_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the index is up-to-date you can call the `udpate_index` method on the bank. This will iterate through all files that are timestamped later than the last time `update_index` was run.\n",
    "\n",
    "You only need to run `update_index` if the directory has not been indexed before or you have added new files to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:13.889830Z",
     "iopub.status.busy": "2020-09-23T18:43:13.883910Z",
     "iopub.status.idle": "2020-09-23T18:43:13.914546Z",
     "shell.execute_reply": "2020-09-23T18:43:13.916230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveBank(base_path=/tmp/tmp1llg3ak4/crandall_test/waveforms)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.update_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get waveforms\n",
    "\n",
    "Now we can get files from the directory with the `get_waveforms` method, which has the same signature as the obspy client get_waveform methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:13.936465Z",
     "iopub.status.busy": "2020-09-23T18:43:13.928686Z",
     "iopub.status.idle": "2020-09-23T18:43:14.043073Z",
     "shell.execute_reply": "2020-09-23T18:43:14.042521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Trace(s) in Stream:\n",
      "TA.O15A..BHE | 2007-08-06T01:44:48.000000Z - 2007-08-06T01:45:48.000000Z | 40.0 Hz, 2401 samples\n",
      "TA.O15A..BHN | 2007-08-06T01:44:47.999998Z - 2007-08-06T01:45:47.999998Z | 40.0 Hz, 2401 samples\n",
      "TA.O15A..BHZ | 2007-08-06T01:44:47.999998Z - 2007-08-06T01:45:47.999998Z | 40.0 Hz, 2401 samples\n",
      "TA.O16A..BHE | 2007-08-06T01:44:48.000000Z - 2007-08-06T01:45:48.000000Z | 40.0 Hz, 2401 samples\n",
      "TA.O16A..BHN | 2007-08-06T01:44:48.000000Z - 2007-08-06T01:45:48.000000Z | 40.0 Hz, 2401 samples\n"
     ]
    }
   ],
   "source": [
    "import obspy\n",
    "\n",
    "t1 = obspy.UTCDateTime('2007-08-06T01-44-48')\n",
    "t2 = t1 + 60\n",
    "st = bank.get_waveforms(starttime=t1, endtime=t2)\n",
    "print (st[:5])  # print first 5 traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, of course, filter on channels, locations, stations, networks, etc. using linux style search strings or regex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:14.053316Z",
     "iopub.status.busy": "2020-09-23T18:43:14.052796Z",
     "iopub.status.idle": "2020-09-23T18:43:14.075366Z",
     "shell.execute_reply": "2020-09-23T18:43:14.075847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Trace(s) in Stream:\n",
      "UU.CTU..HHE | 2007-08-06T01:44:48.004000Z - 2007-08-06T01:45:48.004000Z | 100.0 Hz, 6001 samples\n",
      "UU.CTU..HHN | 2007-08-06T01:44:48.004000Z - 2007-08-06T01:45:48.004000Z | 100.0 Hz, 6001 samples\n",
      "UU.CTU..HHZ | 2007-08-06T01:44:48.004000Z - 2007-08-06T01:45:48.004000Z | 100.0 Hz, 6001 samples\n",
      "UU.MPU..HHE | 2007-08-06T01:44:48.002000Z - 2007-08-06T01:45:48.002000Z | 100.0 Hz, 6001 samples\n",
      "UU.MPU..HHN | 2007-08-06T01:44:48.002000Z - 2007-08-06T01:45:48.002000Z | 100.0 Hz, 6001 samples\n"
     ]
    }
   ],
   "source": [
    "st2 = bank.get_waveforms(network='UU', starttime=t1, endtime=t2)\n",
    "\n",
    "# ensure only UU traces were returned\n",
    "for tr in st2:\n",
    "    assert tr.stats.network == 'UU'\n",
    "\n",
    "print(st2[:5])  # print first 5 traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:14.086957Z",
     "iopub.status.busy": "2020-09-23T18:43:14.085929Z",
     "iopub.status.idle": "2020-09-23T18:43:14.098143Z",
     "shell.execute_reply": "2020-09-23T18:43:14.097589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Trace(s) in Stream:\n",
      "TA.O15A..BHE | 2007-08-06T01:44:48.000000Z - 2007-08-06T01:45:48.000000Z | 40.0 Hz, 2401 samples\n",
      "TA.O15A..BHN | 2007-08-06T01:44:47.999998Z - 2007-08-06T01:45:47.999998Z | 40.0 Hz, 2401 samples\n",
      "TA.O16A..BHE | 2007-08-06T01:44:48.000000Z - 2007-08-06T01:45:48.000000Z | 40.0 Hz, 2401 samples\n",
      "TA.O16A..BHN | 2007-08-06T01:44:48.000000Z - 2007-08-06T01:45:48.000000Z | 40.0 Hz, 2401 samples\n",
      "TA.O18A..BHE | 2007-08-06T01:44:47.999998Z - 2007-08-06T01:45:47.999998Z | 40.0 Hz, 2401 samples\n",
      "TA.O18A..BHN | 2007-08-06T01:44:47.999998Z - 2007-08-06T01:45:47.999998Z | 40.0 Hz, 2401 samples\n"
     ]
    }
   ],
   "source": [
    "st = bank.get_waveforms(starttime=t1, endtime=t2, station='O1??', channel='BH[NE]')\n",
    "\n",
    "# test returned traces\n",
    "for tr in st:\n",
    "    assert tr.stats.starttime >= t1 - .00001\n",
    "    assert tr.stats.endtime <= t2 + .00001\n",
    "    assert tr.stats.station.startswith('O1')\n",
    "    assert tr.stats.channel.startswith('BH')\n",
    "    assert tr.stats.channel[-1] in {'N', 'E'}\n",
    "\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WaveBank also shares the `get_waveforms_bulk` method with the FDSN client for efficiently retrieving a large number of streams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:14.106501Z",
     "iopub.status.busy": "2020-09-23T18:43:14.105987Z",
     "iopub.status.idle": "2020-09-23T18:43:14.197659Z",
     "shell.execute_reply": "2020-09-23T18:43:14.198575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Trace(s) in Stream:\n",
      "TA.O15A..BHZ | 2007-08-06T01:44:42.999998Z - 2007-08-06T01:45:42.999998Z | 40.0 Hz, 2401 samples\n",
      "UU.SRU..HHZ  | 2007-08-06T01:44:47.995000Z - 2007-08-06T01:45:47.995000Z | 100.0 Hz, 6001 samples\n"
     ]
    }
   ],
   "source": [
    "args = [  # in practice this list may contain hundreds or thousands of requests\n",
    "    ('TA', 'O15A', '', 'BHZ', t1 - 5, t2 - 5,),\n",
    "    ('UU', 'SRU', '', 'HHZ', t1, t2,),\n",
    "]\n",
    "st = bank.get_waveforms_bulk(args)\n",
    "print(st )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yield waveforms\n",
    "The Bank class also provides a generator for iterating large amounts of continuous waveforms. For example, if you wanted to run a power detector on the data it might make sense to process one hour at a time with a minute of overlap between the slices. We first need to create a bank on a dataset which has continuous data. For this we will use the TA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:14.207266Z",
     "iopub.status.busy": "2020-09-23T18:43:14.206394Z",
     "iopub.status.idle": "2020-09-23T18:43:17.470601Z",
     "shell.execute_reply": "2020-09-23T18:43:17.469986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading waveform data for ta_test dataset ...\n",
      "finished downloading waveform data for ta_test\n",
      "downloading station data for ta_test dataset ...\n",
      "finished downloading station data for ta_test\n",
      "downloading event data for ta_test dataset ...\n",
      "finished downloading event data for ta_test\n"
     ]
    }
   ],
   "source": [
    "ds = obsplus.load_dataset('TA_test')\n",
    "ta_bank = obsplus.WaveBank(ds.waveform_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:17.476058Z",
     "iopub.status.busy": "2020-09-23T18:43:17.474647Z",
     "iopub.status.idle": "2020-09-23T18:43:18.129345Z",
     "shell.execute_reply": "2020-09-23T18:43:18.128875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 6 streams from 2007-02-15T00:00:09.999998Z to 2007-02-15T01:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T00:59:59.999998Z to 2007-02-15T02:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T01:59:59.999998Z to 2007-02-15T03:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T02:59:59.999998Z to 2007-02-15T04:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T03:59:59.999998Z to 2007-02-15T05:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T04:59:59.999998Z to 2007-02-15T06:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T05:59:59.999998Z to 2007-02-15T07:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T06:59:59.999998Z to 2007-02-15T08:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T07:59:59.999998Z to 2007-02-15T09:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T08:59:59.999998Z to 2007-02-15T10:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T09:59:59.999998Z to 2007-02-15T11:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T10:59:59.999998Z to 2007-02-15T12:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T11:59:59.999998Z to 2007-02-15T13:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T12:59:59.999998Z to 2007-02-15T14:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T13:59:59.999998Z to 2007-02-15T15:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T14:59:59.999998Z to 2007-02-15T16:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T15:59:59.999998Z to 2007-02-15T17:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T16:59:59.999998Z to 2007-02-15T18:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T17:59:59.999998Z to 2007-02-15T19:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T18:59:59.999998Z to 2007-02-15T20:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T19:59:59.999998Z to 2007-02-15T21:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T20:59:59.999998Z to 2007-02-15T22:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T21:59:59.999998Z to 2007-02-15T23:00:59.999998Z\n",
      "got 6 streams from 2007-02-15T22:59:59.999998Z to 2007-02-16T00:00:59.999998Z\n"
     ]
    }
   ],
   "source": [
    "# get a few hours of kemmerer data\n",
    "ta_t1 = obspy.UTCDateTime('2007-02-15')\n",
    "ta_t2 = obspy.UTCDateTime('2007-02-16')\n",
    "\n",
    "for st in ta_bank.yield_waveforms(starttime=ta_t1, endtime=ta_t2, duration=3600, overlap=60):\n",
    "    print (f'got {len(st)} streams from {st[0].stats.starttime} to {st[0].stats.endtime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put waveforms\n",
    "You can also add files to the bank by passing a stream or trace to the `bank.put_waveforms` method. WaveBank, however, does not do any file merging so you might end up with overlaps in data if you are not careful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:18.134453Z",
     "iopub.status.busy": "2020-09-23T18:43:18.133951Z",
     "iopub.status.idle": "2020-09-23T18:43:18.211020Z",
     "shell.execute_reply": "2020-09-23T18:43:18.211688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Trace(s) in Stream:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show that no data for RJOB is in the bank\n",
    "st = bank.get_waveforms(station='RJOB')\n",
    "\n",
    "assert len(st) == 0\n",
    "\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:18.217640Z",
     "iopub.status.busy": "2020-09-23T18:43:18.216394Z",
     "iopub.status.idle": "2020-09-23T18:43:18.404857Z",
     "shell.execute_reply": "2020-09-23T18:43:18.404290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Trace(s) in Stream:\n",
      "BW.RJOB..EHE | 2009-08-24T00:20:03.000000Z - 2009-08-24T00:20:32.990000Z | 100.0 Hz, 3000 samples\n",
      "BW.RJOB..EHN | 2009-08-24T00:20:03.000000Z - 2009-08-24T00:20:32.990000Z | 100.0 Hz, 3000 samples\n",
      "BW.RJOB..EHZ | 2009-08-24T00:20:03.000000Z - 2009-08-24T00:20:32.990000Z | 100.0 Hz, 3000 samples\n"
     ]
    }
   ],
   "source": [
    "# add the default stream to the archive (which contains data for RJOB)\n",
    "bank.put_waveforms(obspy.read())\n",
    "st_out = bank.get_waveforms(station='RJOB')\n",
    "\n",
    "# test output\n",
    "assert len(st_out)\n",
    "for tr in st_out:\n",
    "    assert tr.stats.station == 'RJOB'\n",
    "\n",
    "\n",
    "print(st_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Availability\n",
    "You can also use WaveBank to get availability of data, either as a dataframe or as a list of tuples in the form of [(network, station, location, channel, min_starttime, max_endtime)], which is the same as output by the `availability` method of [Obspy's Earthworm client](https://docs.obspy.org/master/packages/obspy.clients.earthworm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:18.410529Z",
     "iopub.status.busy": "2020-09-23T18:43:18.410020Z",
     "iopub.status.idle": "2020-09-23T18:43:18.506162Z",
     "shell.execute_reply": "2020-09-23T18:43:18.505211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>channel</th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA</td>\n",
       "      <td>O15A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-06 01:44:38.825000</td>\n",
       "      <td>2007-08-07 21:43:51.124998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TA</td>\n",
       "      <td>O16A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-06 01:44:38.825000</td>\n",
       "      <td>2007-08-07 21:43:51.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TA</td>\n",
       "      <td>O18A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-06 01:44:38.824998</td>\n",
       "      <td>2007-08-07 21:43:51.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TA</td>\n",
       "      <td>R16A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-07 02:04:54.500000</td>\n",
       "      <td>2007-08-07 21:43:51.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TA</td>\n",
       "      <td>R17A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-06 01:44:38.825000</td>\n",
       "      <td>2007-08-07 21:43:51.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  network station location channel                  starttime  \\\n",
       "0      TA    O15A              BHE 2007-08-06 01:44:38.825000   \n",
       "1      TA    O16A              BHE 2007-08-06 01:44:38.825000   \n",
       "2      TA    O18A              BHE 2007-08-06 01:44:38.824998   \n",
       "3      TA    R16A              BHE 2007-08-07 02:04:54.500000   \n",
       "4      TA    R17A              BHE 2007-08-06 01:44:38.825000   \n",
       "\n",
       "                     endtime  \n",
       "0 2007-08-07 21:43:51.124998  \n",
       "1 2007-08-07 21:43:51.125000  \n",
       "2 2007-08-07 21:43:51.125000  \n",
       "3 2007-08-07 21:43:51.125000  \n",
       "4 2007-08-07 21:43:51.125000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a dataframe of availability by seed ids and timestamps\n",
    "bank.get_availability_df(channel='BHE', station='[OR]*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:18.528420Z",
     "iopub.status.busy": "2020-09-23T18:43:18.527908Z",
     "iopub.status.idle": "2020-09-23T18:43:18.532550Z",
     "shell.execute_reply": "2020-09-23T18:43:18.533084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TA',\n",
       "  'O15A',\n",
       "  '',\n",
       "  'BHE',\n",
       "  2007-08-06T01:44:38.825000Z,\n",
       "  2007-08-07T21:43:51.124998Z),\n",
       " ('TA',\n",
       "  'O16A',\n",
       "  '',\n",
       "  'BHE',\n",
       "  2007-08-06T01:44:38.825000Z,\n",
       "  2007-08-07T21:43:51.125000Z),\n",
       " ('TA',\n",
       "  'O18A',\n",
       "  '',\n",
       "  'BHE',\n",
       "  2007-08-06T01:44:38.824998Z,\n",
       "  2007-08-07T21:43:51.125000Z),\n",
       " ('TA',\n",
       "  'R16A',\n",
       "  '',\n",
       "  'BHE',\n",
       "  2007-08-07T02:04:54.500000Z,\n",
       "  2007-08-07T21:43:51.125000Z),\n",
       " ('TA',\n",
       "  'R17A',\n",
       "  '',\n",
       "  'BHE',\n",
       "  2007-08-06T01:44:38.825000Z,\n",
       "  2007-08-07T21:43:51.125000Z)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.availability(channel='BHE', station='[OR]*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Gaps and uptime\n",
    "WaveBank can also return a dataframe of missing data with the `get_gaps_df` method, as well as return a dataframe of reliability statistics. These are useful, for example, if you are trying to assess the completeness of an archive of contiguous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:18.542109Z",
     "iopub.status.busy": "2020-09-23T18:43:18.537850Z",
     "iopub.status.idle": "2020-09-23T18:43:18.579710Z",
     "shell.execute_reply": "2020-09-23T18:43:18.578878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>channel</th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>sampling_period</th>\n",
       "      <th>path</th>\n",
       "      <th>gap_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA</td>\n",
       "      <td>O15A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-06 01:45:48.799998</td>\n",
       "      <td>2007-08-06 08:48:30.024998</td>\n",
       "      <td>0 days 00:00:00.025000</td>\n",
       "      <td>/TA.O15A..BHE__20070806T014438Z__20070806T0145...</td>\n",
       "      <td>0 days 07:02:41.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TA</td>\n",
       "      <td>O15A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-06 08:49:39.999998</td>\n",
       "      <td>2007-08-06 10:47:15.624998</td>\n",
       "      <td>0 days 00:00:00.025000</td>\n",
       "      <td>/TA.O15A..BHE__20070806T084830Z__20070806T0849...</td>\n",
       "      <td>0 days 01:57:35.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TA</td>\n",
       "      <td>O15A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-06 10:48:25.599998</td>\n",
       "      <td>2007-08-07 02:04:54.499998</td>\n",
       "      <td>0 days 00:00:00.025000</td>\n",
       "      <td>/TA.O15A..BHE__20070806T104715Z__20070806T1048...</td>\n",
       "      <td>0 days 15:16:28.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TA</td>\n",
       "      <td>O15A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-07 02:06:04.474998</td>\n",
       "      <td>2007-08-07 02:14:14.100000</td>\n",
       "      <td>0 days 00:00:00.025000</td>\n",
       "      <td>/TA.O15A..BHE__20070807T020454Z__20070807T0206...</td>\n",
       "      <td>0 days 00:08:09.625002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TA</td>\n",
       "      <td>O15A</td>\n",
       "      <td></td>\n",
       "      <td>BHE</td>\n",
       "      <td>2007-08-07 02:15:24.074998</td>\n",
       "      <td>2007-08-07 03:44:08.474998</td>\n",
       "      <td>0 days 00:00:00.025000</td>\n",
       "      <td>/TA.O15A..BHE__20070807T021414Z__20070807T0215...</td>\n",
       "      <td>0 days 01:28:44.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  network station location channel                  starttime  \\\n",
       "0      TA    O15A              BHE 2007-08-06 01:45:48.799998   \n",
       "1      TA    O15A              BHE 2007-08-06 08:49:39.999998   \n",
       "2      TA    O15A              BHE 2007-08-06 10:48:25.599998   \n",
       "3      TA    O15A              BHE 2007-08-07 02:06:04.474998   \n",
       "4      TA    O15A              BHE 2007-08-07 02:15:24.074998   \n",
       "\n",
       "                     endtime        sampling_period  \\\n",
       "0 2007-08-06 08:48:30.024998 0 days 00:00:00.025000   \n",
       "1 2007-08-06 10:47:15.624998 0 days 00:00:00.025000   \n",
       "2 2007-08-07 02:04:54.499998 0 days 00:00:00.025000   \n",
       "3 2007-08-07 02:14:14.100000 0 days 00:00:00.025000   \n",
       "4 2007-08-07 03:44:08.474998 0 days 00:00:00.025000   \n",
       "\n",
       "                                                path           gap_duration  \n",
       "0  /TA.O15A..BHE__20070806T014438Z__20070806T0145... 0 days 07:02:41.225000  \n",
       "1  /TA.O15A..BHE__20070806T084830Z__20070806T0849... 0 days 01:57:35.625000  \n",
       "2  /TA.O15A..BHE__20070806T104715Z__20070806T1048... 0 days 15:16:28.900000  \n",
       "3  /TA.O15A..BHE__20070807T020454Z__20070807T0206... 0 days 00:08:09.625002  \n",
       "4  /TA.O15A..BHE__20070807T021414Z__20070807T0215... 0 days 01:28:44.400000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.get_gaps_df(channel='BHE', station='O*').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:18.593832Z",
     "iopub.status.busy": "2020-09-23T18:43:18.589962Z",
     "iopub.status.idle": "2020-09-23T18:43:18.847660Z",
     "shell.execute_reply": "2020-09-23T18:43:18.846789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>channel</th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>duration</th>\n",
       "      <th>gap_duration</th>\n",
       "      <th>uptime</th>\n",
       "      <th>availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA</td>\n",
       "      <td>M11A</td>\n",
       "      <td></td>\n",
       "      <td>VHE</td>\n",
       "      <td>2007-02-15 00:00:09.999998</td>\n",
       "      <td>2007-02-24 23:59:59.999998</td>\n",
       "      <td>9 days 23:59:50</td>\n",
       "      <td>0 days</td>\n",
       "      <td>9 days 23:59:50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TA</td>\n",
       "      <td>M11A</td>\n",
       "      <td></td>\n",
       "      <td>VHN</td>\n",
       "      <td>2007-02-15 00:00:09.999998</td>\n",
       "      <td>2007-02-24 23:59:59.999998</td>\n",
       "      <td>9 days 23:59:50</td>\n",
       "      <td>0 days</td>\n",
       "      <td>9 days 23:59:50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TA</td>\n",
       "      <td>M11A</td>\n",
       "      <td></td>\n",
       "      <td>VHZ</td>\n",
       "      <td>2007-02-15 00:00:09.999998</td>\n",
       "      <td>2007-02-24 23:59:59.999998</td>\n",
       "      <td>9 days 23:59:50</td>\n",
       "      <td>0 days</td>\n",
       "      <td>9 days 23:59:50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TA</td>\n",
       "      <td>M14A</td>\n",
       "      <td></td>\n",
       "      <td>VHE</td>\n",
       "      <td>2007-02-15 00:00:00.000003</td>\n",
       "      <td>2007-02-25 00:00:00.000003</td>\n",
       "      <td>10 days 00:00:00</td>\n",
       "      <td>0 days</td>\n",
       "      <td>10 days 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TA</td>\n",
       "      <td>M14A</td>\n",
       "      <td></td>\n",
       "      <td>VHN</td>\n",
       "      <td>2007-02-15 00:00:00.000003</td>\n",
       "      <td>2007-02-25 00:00:00.000003</td>\n",
       "      <td>10 days 00:00:00</td>\n",
       "      <td>0 days</td>\n",
       "      <td>10 days 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TA</td>\n",
       "      <td>M14A</td>\n",
       "      <td></td>\n",
       "      <td>VHZ</td>\n",
       "      <td>2007-02-15 00:00:00.000004</td>\n",
       "      <td>2007-02-25 00:00:00.000004</td>\n",
       "      <td>10 days 00:00:00</td>\n",
       "      <td>0 days</td>\n",
       "      <td>10 days 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  network station location channel                  starttime  \\\n",
       "0      TA    M11A              VHE 2007-02-15 00:00:09.999998   \n",
       "1      TA    M11A              VHN 2007-02-15 00:00:09.999998   \n",
       "2      TA    M11A              VHZ 2007-02-15 00:00:09.999998   \n",
       "3      TA    M14A              VHE 2007-02-15 00:00:00.000003   \n",
       "4      TA    M14A              VHN 2007-02-15 00:00:00.000003   \n",
       "5      TA    M14A              VHZ 2007-02-15 00:00:00.000004   \n",
       "\n",
       "                     endtime         duration gap_duration           uptime  \\\n",
       "0 2007-02-24 23:59:59.999998  9 days 23:59:50       0 days  9 days 23:59:50   \n",
       "1 2007-02-24 23:59:59.999998  9 days 23:59:50       0 days  9 days 23:59:50   \n",
       "2 2007-02-24 23:59:59.999998  9 days 23:59:50       0 days  9 days 23:59:50   \n",
       "3 2007-02-25 00:00:00.000003 10 days 00:00:00       0 days 10 days 00:00:00   \n",
       "4 2007-02-25 00:00:00.000003 10 days 00:00:00       0 days 10 days 00:00:00   \n",
       "5 2007-02-25 00:00:00.000004 10 days 00:00:00       0 days 10 days 00:00:00   \n",
       "\n",
       "   availability  \n",
       "0           1.0  \n",
       "1           1.0  \n",
       "2           1.0  \n",
       "3           1.0  \n",
       "4           1.0  \n",
       "5           1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta_bank.get_uptime_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read index\n",
    "You can also read the index directly, although in most cases this shouldn't be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T18:43:18.854024Z",
     "iopub.status.busy": "2020-09-23T18:43:18.852784Z",
     "iopub.status.idle": "2020-09-23T18:43:18.868309Z",
     "shell.execute_reply": "2020-09-23T18:43:18.867574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>channel</th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>sampling_period</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA</td>\n",
       "      <td>M11A</td>\n",
       "      <td></td>\n",
       "      <td>VHN</td>\n",
       "      <td>2007-02-22 19:59:59.999998</td>\n",
       "      <td>2007-02-22 20:59:59.999998</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>/TA/M11A/VHN/2007-02-22T20-00-00.mseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TA</td>\n",
       "      <td>M14A</td>\n",
       "      <td></td>\n",
       "      <td>VHN</td>\n",
       "      <td>2007-02-22 20:00:00.000003</td>\n",
       "      <td>2007-02-22 21:00:00.000003</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>/TA/M11A/VHN/2007-02-22T20-00-00.mseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TA</td>\n",
       "      <td>M11A</td>\n",
       "      <td></td>\n",
       "      <td>VHN</td>\n",
       "      <td>2007-02-22 04:59:59.999998</td>\n",
       "      <td>2007-02-22 05:59:59.999998</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>/TA/M11A/VHN/2007-02-22T05-00-00.mseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TA</td>\n",
       "      <td>M14A</td>\n",
       "      <td></td>\n",
       "      <td>VHN</td>\n",
       "      <td>2007-02-22 05:00:00.000003</td>\n",
       "      <td>2007-02-22 06:00:00.000003</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>/TA/M11A/VHN/2007-02-22T05-00-00.mseed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TA</td>\n",
       "      <td>M11A</td>\n",
       "      <td></td>\n",
       "      <td>VHN</td>\n",
       "      <td>2007-02-15 09:59:59.999998</td>\n",
       "      <td>2007-02-15 10:59:59.999998</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>/TA/M11A/VHN/2007-02-15T10-00-00.mseed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  network station location channel                  starttime  \\\n",
       "0      TA    M11A              VHN 2007-02-22 19:59:59.999998   \n",
       "1      TA    M14A              VHN 2007-02-22 20:00:00.000003   \n",
       "2      TA    M11A              VHN 2007-02-22 04:59:59.999998   \n",
       "3      TA    M14A              VHN 2007-02-22 05:00:00.000003   \n",
       "4      TA    M11A              VHN 2007-02-15 09:59:59.999998   \n",
       "\n",
       "                     endtime sampling_period  \\\n",
       "0 2007-02-22 20:59:59.999998 0 days 00:00:10   \n",
       "1 2007-02-22 21:00:00.000003 0 days 00:00:10   \n",
       "2 2007-02-22 05:59:59.999998 0 days 00:00:10   \n",
       "3 2007-02-22 06:00:00.000003 0 days 00:00:10   \n",
       "4 2007-02-15 10:59:59.999998 0 days 00:00:10   \n",
       "\n",
       "                                     path  \n",
       "0  /TA/M11A/VHN/2007-02-22T20-00-00.mseed  \n",
       "1  /TA/M11A/VHN/2007-02-22T20-00-00.mseed  \n",
       "2  /TA/M11A/VHN/2007-02-22T05-00-00.mseed  \n",
       "3  /TA/M11A/VHN/2007-02-22T05-00-00.mseed  \n",
       "4  /TA/M11A/VHN/2007-02-15T10-00-00.mseed  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta_bank.read_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar Projects\n",
    "`WaveBank` is a useful tool, but it may not be a good fit for every application. Check out the following items as well:\n",
    "\n",
    "Obspy has a way to visualize availability of waveform data in a directory using [obspy-scan](https://docs.obspy.org/tutorial/code_snippets/visualize_data_availability_of_local_waveform_archive.html). If you prefer a graphical option to working with `DataFrame`s this might be for you.\n",
    "\n",
    "Obspy also has [filesystem client](https://docs.obspy.org/master/packages/autogen/obspy.clients.filesystem.sds.Client.html#obspy.clients.filesystem.sds.Client) for working with SeisComP structured archives.\n",
    "\n",
    "[IRIS](https://www.iris.edu/hq/) released a mini-seed indexing program called [mseedindex](https://github.com/iris-edu/mseedindex) which will have an [ObsPy API](https://github.com/obspy/obspy/pull/2206). We personally have not yet used mseedindex but it certainly looks worth checking out."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
